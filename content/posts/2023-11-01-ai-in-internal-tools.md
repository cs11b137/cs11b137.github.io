+++
title = "在内部运营/中台工具里加一点 AI：从搜索到推荐"
date = 2023-11-01
draft = false
categories = ["AI 应用"]
tags = ["内部系统", "运营中台", "智能搜索", "推荐"]
description = "分享几个在内部运营/中台工具中「加一点 AI」的改造案例：搜索、推荐、智能填写，让原本冰冷的表格和配置界面变得更聪明一点。"
+++

相比 C 端产品，「内部运营/中台工具」看起来没那么光鲜，界面经常是：

> 一堆表格、一堆配置、一堆筛选项。

但正因为如此，AI 在这里往往很好落地：

- 用户数量受控，易于试点；  
- 业务流程清晰，方便评估效果；  
- 哪怕只提升一点效率，整体价值也不小。

这篇文章就分享几个我们在内部工具里「加一点 AI」的尝试：从搜索到推荐再到智能填写。

---

## 1. 智能搜索：从「条件筛选」到「自然语言搜索」

### 1.1 传统方式的痛点

运营同学以前查数据要：

1. 打开一个复杂查询页；  
2. 选择 N 个下拉框（业务线、产品、日期区间、状态…）；  
3. 点击查询，发现忘记勾某个条件，再重新来一次。

于是我们考虑加一个入口：**自然语言搜索**。

例如：

> 「最近 7 天上海地区的私募新增高净值客户」  
> 「失败次数超过 3 次的合同签署记录」

### 1.2 技术方案

1. 用大模型把自然语言解析成结构化查询条件；  
2. 再把这些条件映射到后端已有查询接口；  
3. 最终仍然走「原有 SQL / ES 查询逻辑」。

伪代码示意：

```ts
const prompt = `
你是查询构建助手。请将用户的自然语言查询转换为 JSON 条件。...
`;

const llmResult = await callLLM(prompt + userQuery);
const conditions = JSON.parse(llmResult);

const data = await callSearchAPI(conditions);
```

关键点：

- **不直接让模型生成 SQL**（安全风险 & 不可控）；  
- 而是生成一个受控的 JSON 条件对象。

### 1.3 前端体验

- 搜索框下方展示「解析出的条件」，让用户确认；  
- 支持一键切换到「高级筛选」视图，展示同样条件；  
- 避免让 AI 变成黑盒——用户看得见它怎么理解的。

---

## 2. 智能推荐：运营配置页也能变「懂你」一点

场景：

- 运营在后台配置「某类用户看到哪些运营位/推荐产品」；  
- 一般是靠经验拍脑袋选；  
- 想利用历史数据做一点辅助决策。

### 2.1 我们做了什么

在原有「人工配置」的基础上，增加一个「AI 建议」按钮：

1. 把当前页面的配置信息 + 历史数据特征摘要传给后端；  
2. 后端通过简单模型/规则 + 大模型做一个「建议方案」；  
3. 前端弹出一个 diff 视图：现有配置 vs 建议配置。

例如：

> 「针对风险偏好为激进、资产规模 500 万以上的客户，建议优先展示以下 3 个产品，并降低低风险产品的排序权重。」

前端只负责：

- 展示建议；  
- 支持一键应用或手动微调。

### 2.2 几点心得

1. **不要抢运营的权力**  
   - AI 输出的是「建议」，不是强制方案；  
   - 最终修改仍然由运营点击确认。

2. **给出理由**  
   - 简单描述推荐原因，例如「基于最近 30 天的转化率和客户画像」；  
   - 提升信任感。

3. **支持快速回退**  
   - 应用新配置后，允许一键回滚到上一个版本。

---

## 3. 智能填写：帮运营补齐表格里的「脑力劳动」

很多中台表格里都有一些「需要思考一下」的字段，比如：

- 活动配置时的文案；  
- 规则说明；  
- 对账备注、问题标签等。

### 3.1 文案辅助生成

在活动配置页，我们加了一个「AI 生成文案」功能：

1. 运营输入活动目标、目标人群、活动类型等简单描述；  
2. 点击生成按钮，AI 给出若干条候选文案；  
3. 运营可以选中某条，再手动修改。

技术上很简单：

- 把结构化配置 + 文案语气要求传给大模型即可；  
- 前端注意限制字数、样式、敏感词过滤。

### 3.2 问题工单自动打标签

对于内部问题单：

- 以前需要运营/客服手动选择「问题类型」；  
- 现在可以让 AI 根据工单内容推荐几个候选标签：  
  - 「电子合同」/「支付失败」/「权限配置」等。

实现：

- 用小模型做分类也行；  
- 也可以让大模型输出推荐标签列表；  
- 最终仍然由处理人确认或修改。

---

## 4. 风险与边界：内部工具不等于「可以随便来」

尽管是内部系统，仍然要有基本边界：

1. **数据权限**  
   - AI 能看到的数据必须与用户权限一致；  
   - 不要因为接入大模型就绕过既有数据访问控制。

2. **内容安全与合规**  
   - 文案生成要避免违规内容；  
   - 对于涉及合规/风险等级的建议，需加免责声明或强制人工复核。

3. **审计与回溯**  
   - 记录 AI 参与决策的场景（例如某条推荐是 AI 提供的建议）；  
   - 方便事后追踪：这次配置是谁改、是否参考了 AI 建议。

---

## 5. 评估效果：不要只看「爽感」，要看数据

为了避免「玩个新技术就算完事」，我们对每个 AI 功能都设了简单的评估方式：

1. 智能搜索：  
   - 使用率（多少查询用自然语言入口）；  
   - 搜索后「立即修改条件」的比例（侧面反映理解准确度）。

2. 推荐/辅助配置：  
   - 使用建议后 vs 手动配置的转化率对比；  
   - 运营对建议采纳率。

3. 智能填写：  
   - AI 文案被采纳 & 修改率；  
   - 工单标签建议命中率。

这些指标不需要特别复杂，但能帮我们判断：

> 这个 AI 功能是真有用，还是「锦上添花的小玩具」。

---

## 6. 小结：给中台「加一点 AI」的顺序

我的经验是：

1. **从不改变主流程的小功能开始**  
   - 比如智能搜索、文案建议、标签推荐；  
   - 出问题时容易回退。

2. **优先选用频率高、但对准确度要求没那么极端的场景**  
   - 例如搜索、筛选、配置辅助；  
   - 而不是一上来就让 AI 自动做大额决策。

3. **每上一个功能，都想清楚边界和评估方式**  
   - 明确 AI 能做什么、不能做什么；  
   - 上线之后，用数据验证它是不是「真正值得留下」。

内部工具很适合成为 AI 落地的「试验田」：  
迭代成本可控、用户专业且可沟通、效果可测量。  
做着做着，你会发现——那些原本枯燥的表格和配置页，也可以变得聪明一点、人性化一点。

