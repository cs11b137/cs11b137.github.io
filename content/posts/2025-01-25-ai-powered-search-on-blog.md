+++
title = "给个人网站加一个 AI 搜索框"
date = 2025-01-25
draft = false
categories = ["个人网站", "AI 应用"]
tags = ["博客", "搜索", "RAG", "向量检索"]
description = "基于本站内容做语义搜索 / 问答的完整流程记录，从数据准备、向量检索到前端交互和使用体验。"
+++

这篇算是给我自己的一份施工日志：记录我是怎么在个人网站上加一个「AI 搜索框」的。

目标很简单：

> 让搜索不再只靠关键字，而是能用自然语言问问题，基于博客内容给出回答。

比如：

- 「你之前是怎么做前端性能监控的？」  
- 「Monorepo 迁移里有哪些坑？」  
- 「AI 和前端结合有什么实践？」

都可以直接问。

---

## 1. 先想清楚：AI 搜索到底要搜什么？

我给自己的约束：**只基于本站内容**。

- 不接入外部网络  
- 不回答「全球最佳框架是哪一个」这种问题  
- 只回答「我自己写过什么」「我自己是怎么想的」

这样有几个好处：

1. 不用考虑太复杂的内容安全问题  
2. 回答的质量和风格更统一  
3. 搜索结果更像是「帮我找回过去的自己」

---

## 2. 数据准备：从 Hugo 的 Markdown 出发

网站用的是 Hugo，文章都在 `content/posts` 中。

做了一个简单的数据导出脚本：

1. 遍历所有 Markdown 文件  
2. 解析 front matter（标题、日期、标签）  
3. 提取正文内容，按标题层级切分成若干小段  
4. 为每个小段生成一个唯一 ID + 一些元信息

伪代码大概是：

```ts
interface Chunk {
  id: string
  title: string
  date: string
  tags: string[]
  sectionPath: string[]
  content: string
  url: string
}
```

这些 `Chunk` 之后会被送去做向量化。

---

## 3. 向量化与向量库：把内容变成「可相似度检索」的形式

### 3.1 嵌入（Embedding）

对每个片段调用 Embedding 模型，生成一个向量：

```ts
const embedding = await embed(chunk.content)
// embedding: number[]
```

向量和 metadata 一起存起来。

### 3.2 向量库

个人项目，我选了一个轻量的方案：

- 使用托管的向量数据库（或者 SQLite + 向量扩展也行）  
- 每条记录包含：`id + vector + metadata`

需要支持的能力：

- 写入 / 更新向量  
- 按相似度查询 Top K 片段  
- 基于标签 / 日期等做简单过滤（可选）

---

## 4. 检索流程：从问题到候选片段

当有人在博客搜索框里输入：

> 「前端项目里怎么接入 AI Review？」

后台会执行：

1. 对问题做一次 Embedding  
2. 在向量库中查 Top K 片段（比如 8～10 个）  
3. 把这些片段作为上下文，发给大模型，让它基于这些内容来回答

注意：我会在 Prompt 里反复强调：

> 你只能根据给定片段回答问题。  
> 如果片段里没有明确提到，就说「我好像没有在文章里具体写过这一点」。

这样可以尽量降低「瞎编」风险。

---

## 5. Prompt 设计：把模型当成「站内问答助手」

系统提示类似：

> 你是一个基于个人博客内容的问答助手。  
> 我会提供一些文章片段，它们都来自同一个作者的博客。  
> 你需要：  
> 1. 根据片段内容回答用户问题  
> 2. 如果片段内容不足以回答，说明「我在文章里没有写得很详细」  
> 3. 回答风格尽量口语化、简洁，像作者在写博客一样  
> 4. 在合适的地方提一下「相关主题可以参考 XX 文章」，但不要编造不存在的文章。

用户输入则包含：

- 问题文本  
- 命中的片段列表（标题 + 内容摘要）

---

## 6. 前端交互：一个简单但好用的搜索框

前端部分我刻意做得很克制：

- 顶部导航栏加一个搜索入口  
- 打开后是一个全屏弹层：上方输入框，下方是「对话区」  
- 支持多轮提问，保留上下文

交互上的几个小点：

1. **首次提示**  
   - 在输入框下方放几条示例问题  
   - 降低用户不知道问什么的门槛

2. **显示来源**  
   - 每个回答下方附一行「参考自：XXX（2023-09-10）」  
   - 点击可在新窗口打开对应文章

3. **失败兜底**  
   - 如果检索不到相关片段，给出友好提示：  
     > 「我好像还没写过这块，或许可以换个问法，或者哪天我写一篇 😄」

---

## 7. 如何控制成本与延迟？

因为是个人博客，访问量有限，所以相对宽松。  
但还是做了几件事：

1. **前端做简单缓存**  
   - 同一个问题短时间内重复问，直接返回上次结果

2. **限制问题长度和频率**  
   - 超长问题先在前端提示用户缩短  
   - 后端对同一 IP / 浏览器做一些频率保护

3. **尽量减少每次传给模型的上下文长度**  
   - 片段切短一点  
   - 只传最相关的 5～8 个片段

---

## 8. 使用体验：它真的有用吗？

对我自己来说，最大的好处是：

1. 写过的东西更容易「被找回」  
2. 写文章时可以快速查自己之前的观点和实践  
3. 有时候甚至会惊讶：  
   > 「原来我当时这样想过 😂」

对偶然路过的访客来说：

- 不需要熟悉分类 / 标签  
- 用自然语言问问题就好

虽然现在还很简陋，但已经比「只支持标题关键字搜索」要好用很多。

---

## 9. 小结

给个人网站加一个 AI 搜索框，其实就是三件事：

1. 把文章内容结构化、切分、向量化  
2. 用向量检索找到相关片段，喂给大模型回答  
3. 做一个顺手的前端界面，把它变成一个「对话式搜索框」

它不是一个复杂的产品，但对个人来说已经足够有趣：  
**让博客从「往外写」变成「也能向里问」。**